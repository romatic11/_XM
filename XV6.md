# XV6

https://www.yuque.com/chengxuyuancarl/gxfm6r?#	ww03

## xv6系统启动流程是怎么样的？

```
上电（电源启动）
   ↓
引导加载程序从ROM运行
   ↓
加载xv6内核（kernel）到内存（0x80000000）
   ↓
CPU跳转执行 _entry（机器模式） 设置栈指针
   ↓
设置内核栈，进入 start()（C语言）
   ↓
start：配置CPU权限、中断、页表 → 切换到管理模式（mret到 main）
   ↓
main()：初始化子系统和设备
   ↓
调用 userinit() → 创建第一个用户进程（initcode）
   ↓
initcode 执行 exec("/init")
   ↓
运行 /init（初始化控制台、打开fd0/1/2）→ 启动 shell

```

操作系统的任务：在多个应用程序之间公共硬件资源，多个程序之间互不干扰，不同的活动之间又相互影响

进程：每一个用户空间程序，它们有自己的内存和共享的CPU时间

## git

将实验代码提交到GitHub

1. **首先将mit的实验代码克隆到本地**
2. **在github创建一个新的空仓库**
3. **添加git仓库地址**
4. **`git push`命令**用于从将本地的分支版本上传到远程并合并。
5. **将实验代码推送github仓库**

## gdb

可用于调试C程序

常用命令：

continue ： 运行直至遇到一个断点

break ： 

```
在某个地址处设置断点： break *0x3ffffff10e
在某个函数处设置断点： break syscall
在某个文件某行设置断点： break kernel/syscall.c:106
```

查看断点：

```
info break
```

删除断点：

```
delete 断点编号（通过info break 查到）： delete 2
delete 起始断点 - 终止断点： delete 1 - 5
```

print：

```
打印某个变量：print val
```

layout :

GDB 的 TUI（Text User Interface）模式支持使用不同布局来可视化调试过程。通过 `layout` 子命令，可以将界面划分为不同区域，比如源码窗口、汇编窗口、寄存器窗口等。

要启用 TUI 模式，你可以用：

```
(gdb) tui enable
或
(gdb) layout <子命令>
```



```
layout split 	上下分屏显示源码和汇编  上半部分显示源码  下半部分显示对应的汇编指令
layout src		只显示源码
layout asm		只显示汇编指令
layout reg		显示寄存器窗口
```

调试命令：

`r(run)`—— F5【无断点直接运行、有断点从第一个断点处开始运行】**

**`n(next)`** —— 逐过程【相当于F10，为了查找是哪个函数出错了】

**`s(step)`** —— 逐语句【相当于F11，】

### GDB如何单步调试？

假设你已经使用如下命令启动了调试：

```
gdb -tui ./your_program
```

1. 设置断点

```
(gdb) break main  # 或者 break 文件名:行号
```

2. 运行程序

```
(gdb) run
```

3. 单步进入函数（step）

```
(gdb) step
```

4. 单步跳过函数（next）

```
(gdb) next
```

5. 跳出函数（finish）

```
(gdb) finish
```

6. 继续运行（continue）

```
(gdb) continue
```

## I/O和文件描述符

`dup(oldfd)` 返回的新描述符与旧描述符 **共享同一打开文件对象**

## 管道

管道是作为一对文件描述符公开给进程的小型内核缓冲区，一个用于读取，一个用于写入。将数据写入管道的一端使得这些数据可以从管道的另一端读取。管道为进程提供了一种通信方式。

管道相比临时文件至少有四个优势：

- 首先，管道会**自动清理**自己；在文件重定向时，shell使用完`/tmp/xyz`后必须小心删除
- 其次，管道可以**任意传递长**的数据流，而文件重定向需要磁盘上足够的空闲空间来存储所有的数据。
- 第三，管道允许**并行**执行管道阶段，而文件方法要求第一个程序在第二个程序启动之前完成。
- 第四，如果实现进程间通讯，管道的**阻塞**式读写比文件的非阻塞语义更高效。

```
int p[2];
char *argv[2];
argv[0] = "wc";
argv[1] = 0;
pipe(p);
if (fork() == 0) {
    close(0);
    dup(p[0]);
    close(p[0]);
    close(p[1]);
    exec("/bin/wc", argv);
} else {
    close(p[0]);
    write(p[1], "hello world\n", 12);
    close(p[1]);
}

```

`dup(p[0])` 的“新描述符”**并不是凭空冒出来**，而是操作系统按 **“最小可用整数”** 规则自动分配的：

1. 子进程刚 `fork` 完时，描述符状态：

   0 → stdin（终端）
   1 → stdout（终端）
   2 → stderr（终端）
   3 → `p[0]`（管道读端）
   4 → `p[1]`（管道写端）

子进程执行 `close(0);` 现在描述符 **0 被释放**，变成 **最小可用整数**。

接着调用 `dup(p[0]);`

- `dup` 会把 `p[0]` 复制到当前最小可用的描述符，也就是 **0**。

- 返回值 **0** 就直接被忽略（代码里没接收），因为我们要的就是让 **0 指向管道读端**。

`exec("/bin/wc", argv)` 等价于在 shell 里执行 /bin/wc

```
int execv(const char *pathname, char *const argv[]);
pathname: 要执行的程序文件完整路径。这里写 "/bin/wc"，对应系统上的 wc 可执行文件。
argv: 命令行参数数组，必须以 NULL 结尾。数组第 0 个元素惯例上是程序名本身，后面依次是各个参数。
```

## 文件系统

```c
link("a", "b");		创建了一个名字既为a又为b的新文件
  unlink("a");		unlink系统调用从文件系统中删除一个名称。
```

创建**匿名临时文件**  ： 有文件描述符就能用，程序退出后自动彻底消失，无需手动删除。

```
fd = open("/tmp/xyz", O_CREATE | O_RDWR);
unlink("/tmp/xyz");
```

## 页表硬件

Sv39 模式的地址结构

RISC-V 的 Sv39 模式意思是：

- 虚拟地址是 64 位的，但只用低 39 位（高 25 位暂时不用，全是符号扩展位）。

- **39 位虚拟地址结构**：

  ```
  [VPN2 9位] [VPN1 9位] [VPN0 9位] [页内偏移 12位]
  ```

  - 页内偏移：一个页 4KB (2^12)，偏移量告诉你在这个页的哪一字节。
  - VPN（Virtual Page Number）是三级索引：
    - VPN2 → 顶级页表 L2
    - VPN1 → 中间页表 L1
    - VPN0 → 最底层页表 L0
    - 页表的三层查找过程

页表并不是一个超大的数组一次就能查到（那会浪费很多内存），而是三级结构：

1. **satp 寄存器** 存放“根页表”的物理地址。
2. 用虚拟地址的 VPN2 在根页表找到“中间页表”的物理地址。
3. 用 VPN1 在中间页表找到“底层页表”的物理地址。
4. 用 VPN0 在底层页表找到 **PTE（Page Table Entry）**。
5. PTE 里面存着物理页号（PPN）+ 权限标志，拼上“页内偏移”得到最终物理地址。



内存管理单元会将虚拟地址翻译成物理地址.  MMU只是会去查看page table，并不会保存page table

**SATP寄存器**保存表单

## 系统调用

`syscall`

**熟悉系统调用的流程**？

**增加新的系统调用**？

**作用1**：实现一个trace功能，跟踪用户程序的系统调用，并将调用的相关信息打印出来。

**作用2**：使用一个系统调用sysinfo，用来获取空闲的内存、已创建的进程数量。



操作系统通过CPU的特权级模式 将用户态与内核态隔离，保证了用户程序无法直接访问内核资源，避免了误操作和恶意行为。

**用户程序**通过**调用库函数**发生**系统调用**，**系统调用**触发软件**中断或陷阱**，引发CPU切换到**内核态**，内核根据**系统调用号**确定要执行的服务，完成服务后，将**结果或错误码**存入**用户**程序的**寄存器**，并**返回**到用户态继续执行程序。

read执行系统调用流程：

| 步骤 | 名称                             | 描述                                                         | 关键指令/机制   |
| ---- | -------------------------------- | ------------------------------------------------------------ | --------------- |
| 1    | **用户态执行 read 系统调用**     | 用户程序调用 libc 中的 `read()`，最终会触发系统调用。        | `ecall`         |
| 2    | **执行 read 函数**               | 用户态的 `read()` 函数内部会设置参数并触发 `ecall` 指令。    | `ecall`         |
| 3    | **kernel/trampoline.S: uservec** | 内核的系统调用入口，保存用户寄存器、切换到内核栈，跳转到 `usertrap`。 | `uservec`       |
| 4    | **kernel/trap.c: usertrap**      | 内核陷阱处理函数，判断陷阱类型为系统调用，调用 `syscall()`。 | `usertrap()`    |
| 5    | **kernel/syscall.c: syscall**    | 系统调用分发器，根据系统调用号调用对应的处理函数，这里是 `sys_read`。 | `syscall()`     |
| 6    | **sys\_read 函数**               | 实际执行文件读取操作，可能涉及文件描述符、缓冲区、磁盘 I/O 等。 | `sys_read()`    |
| 7    | **kernel/trap.c: usertrapret**   | 系统调用完成后，准备返回用户态，设置返回状态、恢复寄存器。   | `usertrapret()` |
| 8    | **kernel/trampoline.S: userret** | 最终返回用户态，恢复用户寄存器，执行 `sret` 回到用户态。     | `sret`          |

定义函数 `int main(int argc, char *argv[])`里面的argv

```
输入：trace 32 ls
argv[0] = "tarce"
argv[1] = "32"
argv[2] = "ls"
argv[1][0] = '3'
argv[1][1] = '2'
argv[1][2] = '\'
```

### 系统调用流程：

系统执行：trace 32 grep hello README

32(1<<5 = 32) 表示系统调用号掩码为5的系统调用  （在kernel/syscall.h可以看到#define SYS_read	5）

grep是搜索README中的hello

系统调用执行顺序：

```
实现trace系统调用函数（在user/trace.c）

首先在用户空间的头文件user/user.h加入函数声明  （int trace(int)）

在user/usys.pl中，加入用户态到内核态的跳板函数  （entry("trace")  该文件是一个Perl脚本，用于生成usys.S文件，包含用户程序调用内核态系统调用的接口）

在Makefile中添加$U/_trace\

以上是用户态
------------------------------------------------------------------------------------------------------
下面是内核态

在kernel/syscall.h中添加trace的系统调用号（掩码）	#define SYS_trace	22

在kernel/syscall.c中全局声明trace系统调用处理函数，并且把系统调用号与处理函数关联
extren uint64 sys_trace(void)   //全局声明trace系统调用处理函数
[SYS_trace]	sys_trace		  //系统调用号与处理函数关联

在kernel/proc.h里，在进程类proc结构中，添加kama_syscall_trace属性，用掩码的方式记录要跟踪的系统调用
uint64 kama_syscall_trace		存储进程的系统调用跟踪掩码，用于记录哪些系统调用需要被跟踪

在kernel/proc.c中对添加的进程的属性设置默认值0    uint64 kama_syscall_trace = 0

在fork函数中，子进程能继承父进程的这个属性  np->uint64 kama_syscall_trace = p -> uint64 kama_syscall_trace

在kernel/sysproc.c中实现这个系统调用，为进程的kama_syscall_trace属性赋值，用户进程传进来的要跟踪的系统调用号

所有的系统调用都会在kernel/syscall.c的syscall()函数中进行处理，打印跟踪信息

```

Lab**熟悉系统调用的流程**？

系统调用的用户空间代码在***user/user.h***和***user/usys.pl***中

内核空间代码是***kernel/syscall.h***、***kernel/syscall.c***

与进程相关的代码是***kernel/proc.h***和***kernel/proc.c***

1 首先我们在**user/user.h**里提供一个用户的接口

2 接着在**user/usys.pl**里为这个函数加入一个entry(使用汇编语言，将这个函数放到寄存器里，使用ecall指令切换到内核态)

3 为**struct proc**加上记忆需要**trace**的bit mask

4 实现内核态下的**sys_trace**函数, 用**argint**函数从寄存器拿参数, 用**myproc**获得当前进程的一个指针

5  为这个sys_trace提供一个代号和函数指针的mapping. 并且顺手加上一个从代号到名字的mapping, 便于print

6 最后我们修改通用入口syscall函数, 让它print出需要trace的系统调用

## 页表

**有用户态页表 和 内核态页表**：

​	**用户态页表是每个进程独有的** → 隔离进程内存

​	**内核态页表是所有进程共享的** → 内核访问统一

​	切换进程时，只需要切换 **用户态页表部分**，内核部分无需更改



**页表的作用：**

1.  每个进程看到的是自己独立的虚拟地址空间，互相隔离。
2.  虽然虚拟地址是私有的，但它们都可以映射到同一块物理内存。
3.  可以把一块物理内存映射到多个不同的虚拟地址（**共享内存底层实现原理**），也可以留空不映射。

RISC-V:

1. CPU取指、访存时用的都是虚拟地址（VA）。
2. 实际物理内存是通过物理地址（PA）来索引的。

SV39模式下的地址结构：（虚拟空间）

1. 虚拟地址（64位）里只用低39位，高25位固定为符号位扩展。
2. 39位里面的前27位用于页表索引，后12位是页内偏移。
3. 页表条目（PTE）包含：
   1. PPN（物理页号，高44位）
   2. 权限与状态位（R/W/X）

三级页表结构：（硬件架构）

1. SV39用的是3级页表树：根页表–>中间页表–>叶子页表。
2. 每级页表都是4KB，含512个PTE
3. 每级索引用9位（2^9=512）,所以：
   1. VA[38:30]:一级索引
   2. VA[29:21]:二级索引
   3. VA[20:12]:三级索引
   4. VA[11:0]: 页内偏移
4. 找到三级的PTE后，把其中的PPN（物理页号，高44位）和页内偏移拼接，得到物理地址。

物理地址 = (物理页号 PPN << 12) | 页内偏移

**TLB**

对于一个虚拟内存地址的寻址，需要读三次内存，代价有点高。实际中，几乎所有的处理器都会对最近使用过的虚拟地址的翻译结果有缓存。

TLB会保存虚拟地址到物理地址的映射关系。这样下一次访问同一个虚拟地址时，处理器可以查看TLB，TLB会直接返回物理地址，而不是通过page table得到结果。

**XV6启动**

从0X1000物理地址启动存放在主板里面的Boot ROM, Boot ROM完成初始化后，跳到0X8000 0000,这是DRAM的起始地址，也是内核代码加载的位置。

**刚启动时的页表**

启动的时候：还没有动态分配page(还没有用malloc/kalloc)

xv6会先构造一个简单的内核虚拟地址空间：

低于PHYSTOP的部分，直接映射到物理地址

这样0X8000就可以直接访问DRAM。

其他的映射到对应的IO设备。

**Kernel Stack + Guard Page**：

**Guard Page**：

就是一个没有设置 `Valid` 位的 PTE → 不映射到物理内存。

如果栈溢出到这里 → **立即触发 page fault**（panic）

作用：防止静默的内存破坏

**Kernel Stack 双映射**：

在高地址映射一次（上面有 Guard Page 保护）

在 PHYSTOP 以下的 **kernel data** 区映射一次

实际运行时主要用高地址版本（安全）

**Kernel text 与 Kernel data 的权限**

**Kernel text**（代码段）

- 标志位：`R-X`（可读，可执行，不可写）
- 防止代码被意外改写，及早发现 bug

**Kernel data**（数据段）

- 标志位：`RW-`（可读写，不可执行）
- 防止数据伪装成代码被执行

### **Free memory（用户进程使用）**

- 用途：
  - 存放用户进程的页表（page table）
  - 用户代码段（text）
  - 用户数据段（data）
- 分配过程：
  1. fork/exec 新进程时，从 Free memory 分配物理页
  2. 填充 PTE（权限、映射关系）
  3. 内核切换到这个进程时，把进程的根页表地址加载到 **SATP**
  4. CPU 开始用进程自己的虚拟地址空间

启动时 CPU 从 0x1000 Boot ROM 起步 → 跳到 0x80000000 内核代码（物理地址） → xv6 设置一个内核虚拟地址空间（大部分直接映射） → 用 Guard Page、权限标志保护关键区域 → Free memory 负责承载所有用户态进程的数据和页表。

![image-20250811162603350](D:/Typora%E5%9B%BE%E7%89%87%E4%BD%8D%E7%BD%AE/image-20250811162603350-1756124684408-15.png)

### 第二个实验

传统 xv6 的做法：

- 整个内核只维护**一张全局内核页表** `kernel_pagetable`，所有进程在内核态都用这一张。进程可以会意外访问其他进程的数据。

- 进程从用户态陷入内核后，用 `kernel_pagetable`，返回用户态前再切回 `p->pagetable`。

**改进操作：**

新增的： **进程专属**的“内核页表”

​		**隔离性**：不同进程在内核态也跑在不同的页表，防止一个进程把另一个进程的内核内存踩坏

​		**性能**：为每个进程预先映射好它常用的内核数据，减少 TLB shootdown。

重点：创建allocproc() 和 销毁freeproc()

- ```
  你新增 `kama_kernelpgtbl` 后，proc 结构体里就有了“用户页表 + 内核页表”两张页表，后续只要保证：
  
  - 进入内核 → 把 `satp` 换成 `p->kama_kernelpgtbl`；
  - 返回用户 → 把 `satp` 换成 `p->pagetable`；
  - 进程创建/销毁时正确建立/释放这张内核页表即可。
  ```

接下来处理：**内核栈**

原本的 xv6 设计中，所有处于内核态的进程都**共享同一个页表**，即意味着共享同一个地址空间。由于 xv6 支持多核/多进程调度，同一时间可能会有多个进程处于内核态，所以需要对所有处于内核态的进程**创建其独立的内核态内的栈**，也就是**内核栈**，供给其内核态代码执行过程。

**在已经添加的新修改中，每一个进程都会有自己独立的内核页表。而现在需要每个进程只访问自己的内核栈，所以可以把每个进程的内核栈映射到各自内核页表的固定位置**（不同页表内的同一逻辑地址，指向不同物理内存）

`procinit()` 原来是“**启动时就把所有进程的内核栈一次性分配并映射**”，你现在把它改成“**只初始化锁，栈和映射推迟到真正创建进程时再处理**”，从而为“每个进程独享内核页表”做准备。

allocproc：为进程创建独立的内核页表，然后将**专属的内核栈固定到内核页表的固定位置**，**建立映射**。

这样 allocproc() 就完整地“创建了一个用户页表 + 私有内核页表 + 独立内核栈的进程槽位”。

这里按创建的顺序反着来，**先释放进程的内核栈，再释放进程的内核页表**

**问题**：进程的页表被释放了，对应的，页表的物理页为啥不能释放？页表和物理页不是一一对应的关系吗？页表用不上了，释放了，对应的物理页应该也用不上了，为啥不能被释放？

**答**：物理页的资源不是只有这一个进程用，也就是说不同的进程的内核页表都映射同一部分物理资源，所以不能释放

### 第三个实验

上一个实验已经让每一个进程都有独立的内核态页表了，该实验需要**将用户态的映射添加到每个进程的内核页表**，也就是将用户态的页表复制到内核态的页表。这样**使得内核态也可以对用户态传进来的指针（逻辑地址）进行解引用**。（内核态可以使用用户态）

两个问题：

1. 原来的用户空间如何跟内核空间之间传递数据的？ （实验三）
2. 修改了什么页表机制 页表是什么？（1. 实验二 独立页表 独立栈 实验三 ）

步骤一：

	vm.c实现一个复制页表的函数   将 src 页表的一部分页映射关系拷贝到 dst 页表中。只拷贝页表项，不拷贝实际的物理页内存

步骤二：

```
再实现一个缩减内存的函数，用于内核页表和用户页表内存映射的同步 
与 uvmdealloc 功能类似，将程序内存从 oldsz 缩减到 newsz，但不释放实际内存
```

步骤三：

```
xv6内核中，用于映射程序内存的地址范围是[0,PLIC)
需要把进程的程序内存映射到其内核页表的这个范围，首先确认这个范围内没有和其他映射冲突。
```

步骤四：

```
把冲突的CLINT这个映射去掉
```

步骤五：

```
这样进程的内核页表中就不会有程序内存映射和CLINT映射冲突的问题了。但是这个映射是内核启动所必须的，所以可以在全局内核页表初始化中加上这个映射
```

步骤六：

```
接下来在 kernel/exec.c中的exex() 中加入检查，防止程序内存超过 PLIC
```

步骤七：

```
接下来涉及到用户态页表的修改，都要把相应的修改同步到进程的内核页表中，包括：﻿fork()﻿、﻿exec()﻿、﻿growproc()﻿、﻿userinit()  
fork将新进程用户页表映射拷贝一份到新进程内核页表中
exec清除内核页表中对程序内存的旧映射，然后重新建立映射
growproc内核页表的映射同步扩大与缩小
同步程序内存映射到进程内核页表中
```

步骤八：

```
按照实验要求替换﻿copyin﻿、﻿copyinstr
新添加的函数、修改了传参的函数要去﻿defs.h﻿中做出对应的调整，不然程序会找不到对应的函数调用。
```

内核的`copyin`函数读取用户指针指向的内存。它通过将用户指针转换为内核可以直接解引用的物理地址来实现这一点。这个转换是通过在软件中遍历进程页表来执行的。在本部分的实验中，您的工作是将用户空间的映射添加到每个进程的内核页表（上一节中创建），以允许`copyin`（和相关的字符串函数`copyinstr`）直接解引用用户指针。

最终做法：用户和内核地址进行**映射**以**避免**在用户和内核空间之间切换时必须**切换**页表。

原来是用户态 切换 内核态 系统调用 。现在是用户态就可以使用页表映射到内核态。

## 中断处理

`做完lab后可以梳理总结一下系统调用的全流程，面试常考题`

三种触发事件（导致CPU打断当前指令执行）：

1. 系统调用
2. 异常
3. 中断

 一般陷阱（中断）处理流程：

1. ```
   1. cpu切换到内核态
   2. 内核态保存寄存器上下文
   3. 执行中断处理程序
      1. 系统调用—-posix接口
      2. 异常 —– 异常处理 杀死
      3. 中断 —- 设备驱动程序
   4. 内核恢复上下文
   5. 返回继续执行
   ```

 **RISC-V CPU 的陷阱相关寄存器** stvec  保存 **陷阱处理程序的入口地址**。

 **RISC-V CPU 在陷阱发生时，硬件只做最小化的动作：记录 PC（程序计数器）、模式、原因，然后跳转到 `stvec`；真正的寄存器保存、栈切换、页表切换由内核完成。这种设计保证了灵活性和安全性。**

### 用户态陷阱的特殊难点

**用户页表不映射内核代码/数据** → 不能直接执行内核函数。

**用户栈可能无效/恶意** → 内核不能依赖它。

**RISC-V 硬件不会切换页表** → 必须自己切换。

解决方案：**trampoline 机制**

- `uservec` 必须既能在用户页表下运行，又能在切换后继续运行。
- xv6 把 **trampoline.S** 的一页代码映射到
  - 用户页表
  - 内核页表的 **相同虚拟地址 TRAMPOLINE**。
- 因此，不论当前页表是谁，执行到的都是同一个 trampoline 入口。

```
用户态执行中
   │
   ▼
陷阱发生 → CPU跳到 stvec=uservec (trampoline)
   │
   ▼
uservec (汇编)：保存寄存器，切换页表，进入内核
   │
   ▼
usertrap (C)：判断陷阱类型 → syscall/devintr/kill
   │
   ▼
usertrapret (C)：准备返回参数
   │
   ▼
userret (汇编)：切换回用户页表，恢复寄存器
   │
   ▼
sret → 回到用户程序

```

xv6 用 **trampoline 机制**保证了“用户态陷阱 → 内核态处理 → 返回用户态”的无缝切换：uservec 和 userret 在 trampoline 上运行，完成寄存器保存/恢复、页表切换；C 函数 usertrap 和 usertrapret 负责真正的处理逻辑。



### 1. **COW fork (写时拷贝 fork)**

- **普通 fork（xv6 原版）**：父进程的内存 → 全部复制一份 → 给子进程。
  🚨 缺点：非常耗时、浪费内存。
- **COW fork**：
  - 父子进程**最开始共享同一份物理内存**，页表里都标记成 **只读**。
  - 如果某一方要写，CPU 检测到写只读页 → 触发 **页面错误**。
  - 内核这时才真正复制那一页内存，给双方一人一份可写的。
    → 大部分情况下，子进程很快会 `exec` 覆盖内存，所以复制的页数很少。

### 2. **惰性分配 (Lazy allocation)**

- 程序调用 `sbrk` 要更多内存时，内核并不会立刻分配物理页，只是 **在页表里留个空壳 (无效映射)**。
- 当程序真正访问那块地址时 → 页面错误 → 内核才分配物理页。
  → 好处：节省内存，只在真正需要时分配。

### 3. **分页 (Paging / Swap)**

- 如果物理内存不够，内核会把某些页写到磁盘上（swap out），页表里标记为无效。
- 当程序再访问那块内存 → 页面错误 → 内核从磁盘读回来（swap in），再更新页表。
  → 好处：让程序能用比实际物理内存更大的地址空间。

### 4.**trampoline page**（跳板页）

trampoline page 就是一小段特殊的内存代码，用来 **切换用户态和内核态**。

直接跳是不行的，因为用户页表和内核页表映射的区域不一样。所以内核会准备一块“全局相同的代码”，不管在哪个进程里都能用，这就是 **trampoline**。

通常映射在用户地址空间的 **最高一页**，但实际内容存放在内核里，用户进程不能随意修改。

主要是两部分：

1. 从用户态跳到内核态的入口（保存寄存器、切换栈）。
2. 从内核态返回用户态的入口（恢复寄存器、回到用户栈）。

**trampoline page 是一块共享的跳板代码，负责在用户态和内核态之间安全切换。**



**程序计数器PC**： 表明当前mode的标志位是**内核模式**还是**用户模式**。

**SATP**：包含了指向page table的物理内存地址

**trap处理的过程中需要改变的状态：**

1. 保存32个用户寄存器、
2. mode需要改为supervisor mode （将SATP寄存器指向kernel page table）
3. 需要将堆栈寄存器指向位于内核的一个地址，用堆栈来调用内核的函数。一旦设置好，并且所有的硬件状态都适合在内核中使用，需要跳入内核的代码。
4. 不能让用户代码介入到这里的user/kernel切换，否则有可能会被破坏安全性。

### Trap代码执行流程

用户程序执行系统调用函数（实际上通过执行**ECALL指令**来执行系统调用）

用户程序—>ecall—>uservec（在trampoline中）—–>usertrap（在trap.c中）—>syscall—->sys_xxx(对应的系统调用)—>执行结果返回给syscall—->usertrapret(在trap.c中)—->userret（在trampoline中）—>系统调用完成、返回到用户空间，恢复ECALL之后的用户程序的执行。

#### ecall指令

`ecall` 会让 CPU 从 **user mode** 切换到 **supervisor mode**。

**不会切换页表**（非常关键）！

CPU 的程序计数器跳转到 **trampoline page** 的起始地址，这个 page 中包含内核的 trap 处理代码。

每个进程的 **user page table** 中都映射了 trampoline page，但映射到 **同一个物理地址**。

内核通过 **STVEC 寄存器** 指定 trampoline page 的起始位置。

**ecall 执行的三件事**

1. CPU 从用户模式切换到 supervisor 模式
2. 将当前程序计数器保存在 **SEPC 寄存器**
3. 将 STVEC 中的地址加载到程序计数器，开始执行 trampoline page 中的内核代码

即：

ecall 触发系统调用，完成三件事：

1. 切到内核态  
2. 保存返回地址  
3. 跳到内核入口继续执行

### 实验二

是打印曾经调用过的函数的地址，打印出调用栈，用于调试。

### 实验三

该实验需要实现﻿**sigalarm**﻿ 和 ﻿**sigreturn**﻿两个系统调用， **为用户进程添加定期通知功能**，使得进程在一段时间内使用 CPU 后，会被定期“提醒”， 类似于一种   **用户态的中断处理**  ，用来模拟用户级的异常处理。

sigalarm﻿ 和 ﻿sigreturn﻿都是系统调用。这里把alarm相关的字段添加到进程的结构体中：

```
kama_alarm_interval：时钟周期，0 为禁用

kama_alarm_handler：时钟回调处理函数

kama_alarm_ticks：下一次时钟响起前还剩下的 ticks 数

kama_alarm_trapframe：时钟中断时刻的 陷阱帧，用于中断处理完成后恢复原程序的正常执行

kama_alarm_goingoff：是否已经有一个时钟回调正在执行且还未返回（用于防止在 alarm_handler 中途闹钟到期再次调用 alarm_handler，导致 alarm_trapframe 被覆盖，﻿user/alarmtest.c﻿中的test2就是测这个的）
```



## 惰性分配

**建议**：`可以总结一下使用懒分配策略的优缺点`

### 页面错误异常（page fault）

Risc-v有三种不同的页面错误：

**加载页面错误**：当加载指令访问的虚拟地址找不到对应的物理地址时触发。
**存储页面错误**：当存储指令访问的虚拟地址找不到对应的物理地址时触发。
**指令页面错误**：当指令获取的虚拟地址找不到对应的物理地址时触发。

这些页面错误信息保存在 RISC-V 的两个寄存器中：﻿scause﻿：指示页面错误的类型（加载、存储或指令）；﻿stval﻿：保存无法转换的虚拟地址。

当发生 page fault 时，内核需要三个关键信息：

1. **出错的虚拟地址** → 在 STVAL 寄存器中。
2. **出错的原因（读/写/取指）** → 在 SCAUSE 寄存器中。
3. **触发异常的指令地址** → 在 SEPC 寄存器中。

这三个信息就是内核处理 page fault 的“线索”：

- *在哪里出错了（STVAL）*，
- *为什么出错（SCAUSE）*，
- *是谁出错（SEPC）*。

### 写时复制COW

- **普通 fork（xv6 原版）**：父进程的内存 → 全部复制一份 → 给子进程。
  🚨 缺点：非常耗时、浪费内存。
- **COW fork**：
  - 父子进程**最开始共享同一份物理内存**，页表里都标记成 **只读**。
  - 如果某一方要写，CPU 检测到写只读页 → 触发 **页面错误**。
  - 内核这时才真正复制那一页内存，给双方**一人一份**可写的。
    → 大部分情况下，子进程很快会 `exec` 覆盖内存，所以复制的页数很少。

### 惰性分配

- 程序调用 `sbrk` 要更多内存时，内核并不会立刻分配物理页，只是 **在页表里留个空壳 (无效映射)**。
- 当程序真正访问那块地址时 → 页面错误 → 内核才分配物理页。
  → 好处：节省内存，只在真正需要时分配。

### 页面换出（分页）

- 如果物理内存不够，内核会把某些页写到磁盘上（swap out），页表里标记为无效。
- 当程序再访问那块内存 → 页面错误 → 内核从磁盘读回来（swap in），再更新页表。
  → 好处：让程序能用比实际物理内存更大的地址空间。

### 实验一

只记录分配了多少内存，但是不做实际的分配。

`sbrk(n)` → 增加/减少堆空间。

- `n > 0` → 申请内存
- `n < 0` → 释放内存
- `n = 0` → 返回当前堆顶

修改后的版本做了 **惰性分配**：

- `n > 0` 时 **不立刻分配物理页**，只增加 `sz`。
- 访问新地址时再通过 page fault 分配物理页。

释放内存时还是要立刻回收（`uvmdealloc`）。

### 实验二

处理缺页异常

获取异常原因，其中13表示﻿page load fault﻿，15表示﻿page write fault﻿，﻿stval﻿表示引发缺页异常的虚拟地址，缺页异常就可以由﻿(r_scause() == 13 || r_scause() == 15)﻿表示。

先判断发生错误的虚拟地址是否位于栈空间之上，进程大小之下（虚拟地址从0开始，进程大小可以表示进程的最高虚拟地址），然后为其分配物理内存并添加映射



**重点**：

上一个实验在 `sys_sbrk` 里只是增加了进程的 `sz`，并没有真正分配物理内存。

所以当用户程序第一次访问新申请的地址时，会触发 **page fault**。

硬件把出错地址放在 **STVAL**，原因放在 **SCAUSE**。

于是内核在 `usertrap` 里拦截到这个异常，进行处理。



都是适应惰性分配的

**分配内存：**

第一段代码：

这段 `usertrap` 实现了 xv6 的 **按需分配 (Lazy Allocation)**。它的核心思想是：

- `sys_sbrk` **只增加 sz，不分配页**。
- **第一次访问地址时触发缺页异常**，才真正分配物理页并建立映射。

**释放内存：**

第二段代码：

在原版 xv6 里，`uvmunmap` 假设所有地址都必须映射成功，否则 panic。
 但你现在做了 **惰性分配**：

- 某些虚拟地址（比如 `sbrk` 申请的）可能用户压根没访问过，所以对应的页表项 **根本不存在**。
- 在这种情况下，如果还 panic，系统就跑不起来了。
- 所以你改成 **continue**，跳过这些“空洞”，逻辑就合理了。



这个版本的 `uvmunmap`：

1. 遍历每一页虚拟地址；
2. 如果页表项不存在 / 无效，就 **跳过**（兼容惰性分配）；
3. 如果页表项有效，就：
   - （可选）释放物理页；
   - 清空页表项。

🔑 改动的核心思想：
 👉 **支持惰性分配**，允许进程声明的虚拟地址空间比实际分配的物理页大，不会因为 unmapped 地址导致 panic。

## 写时复制

**普通 fork()**：会给子进程逐页拷贝父进程的内存内容（物理页 → 新物理页），子进程和父进程完全独立。

**COW fork()**：不拷贝实际物理页，而是让子进程的页表条目（PTE）直接指向父进程已有的物理页。这样父子共享内存，节省了内存和拷贝时间。

COW fork()将父进程和子进程中的所有用户PTE标记为不可写。

当任一进程试图写入其中一个COW页时，CPU将强制产生页面错误。

这就是 COW 的关键点：

- 读操作安全（共享即可）。
- 写操作触发异常 → 内核介入。

在普通 fork() 中，每个物理页只属于一个进程，进程退出时直接释放物理页就行。

但在 **COW fork()** 中：

- 一个物理页可能同时被父进程、子进程，甚至多个子进程引用。
- 如果其中一个进程释放时直接 `kfree`，其他还在用的进程就会崩溃（悬空引用）。

**COW fork 把父子进程的虚拟内存映射到相同物理页上，并通过“不可写 + 缺页异常 + 内核拷贝”来延迟复制数据，从而提升效率。但因为物理页会被多个进程共享，不能再随便释放，必须引入引用计数，只有最后一个持有者退出时才能真正释放。**



原本的xv6中，一个物理页只会在一个进程中有映射，﻿kalloc﻿用来分配物理页，﻿kfree﻿用来回收物理页。在COW机制中，一个物理页会在多个进程中有映射，所以要在最后一个映射释放的时候，才真正释放回收该物理页，结合这些，需要实现以下操作：

●	kalloc﻿: 分配物理页，将其引用数置为 1

●﻿	kama_krefpage﻿: 创建物理页的一个新映射的时候，引用数+1

●﻿	kama_kcopy_n_deref﻿: 将原物理页的数据复制到一个新物理页上（引用数为 1），返回得到的新物理页；并将原物理页的引用数-1

●﻿	kfree﻿: 释放物理页的一个映射，引用数减 1；如果引用数变为 0，则释放回收物理c

## 多线程

线程的状态包含了三个部分：

1. 程序计数器，它表示当前线程执行指令的位置
2. 保存了变量的寄存器
3. 程序的Stack。每个线程都有属于自己的Stack，Stack记录了函数调用的记录，并反映了当前线程的执行点线程会运行在所有可用的CPU核上，每个CPU核会在多个线程之间切换。

线程之间可用锁来协调



### 在用户态实现协程

- 协程（Coroutine）和进程/线程的差别在于：协程切换不需要陷入内核态，只在 **用户态保存/恢复执行现场**（主要是寄存器和栈）。
- 参考 xv6 的上下文切换思路，你可以在用户态写一个 **context 保存结构**（保存 `rip`/`rsp` 等寄存器），并在 `yield()` 时手动保存现场、恢复另一个协程的现场，就实现了用户态调度。
  👉 意义：加深对 **操作系统级调度和用户态调度的差别** 的理解。

## 锁

怎么降低锁竞争？

怎么处理死锁问题？

###  原因

- xv6 的很多数据结构使用 **大粒度锁**（如对整张页表、整张缓存表加锁）。
- 在多核场景下，这种锁方式容易出现 **锁争用**，导致性能下降。

### 🔹 改进思路

- **更换数据结构**：比如把全局链表换成哈希表或分段式链表。
- **优化锁策略**：
  - 从 **大锁 → 小锁**（Fine-grained Locking）；
  - 或者采用 **分片锁**（不同 CPU/不同数据段独立加锁）；
  - 在缓存块管理时，可以让每个块有自己的锁，而不是整张表一个锁。

👉 意义：理解操作系统在多核环境下的 **锁粒度与并发性能权衡**。

## 文件系统

### xv6 文件系统的限制

- xv6 文件系统采用 **inode + 直接块 + 间接块** 的方式存储数据：
  - 12 个直接块指针
  - 1 个间接块（存放 128 个数据块地址）
- 块大小是 1KB，因此最大文件大小大约是：

```
12 * 1KB + 128 * 1KB = 140KB（老版本）
或者 268KB（根据不同实现）
```

### 如何扩展

- 增加 **二级/三级间接块**（类似 ext2/3/4 的设计）；
- 或者增加直接块的数量。

这样就能把文件最大大小扩展到 **65MB（65803KB）**。

👉 意义：理解文件系统 **inode 结构与文件大小限制的关系**。

## 4️⃣ 实现软链接

### 🔹 xv6 默认支持硬链接，不支持软链接

- 硬链接：多个目录项指向同一个 inode。
- 软链接（符号链接）：目录项存储的是“目标文件路径”，相当于 Windows 的快捷方式。

### 🔹 如何实现

- 新增一种文件类型 `T_SYMLINK`；
- 在 `open()` 系统调用中，当遇到 `T_SYMLINK` 时，先读取路径字符串，再去真正的文件 inode。
- 支持多级解析时需要注意 **避免循环引用**。

👉 意义：理解文件系统的 **链接机制**，以及 Linux 的 `ln -s` 的实现原理。
